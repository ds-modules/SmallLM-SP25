{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b588f-07a1-4d4d-af3e-566bea7e599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    !pip install openai\n",
    "    from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fee75-6964-45a3-a75b-d9c154fad9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_API_KEY =\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5434c-dcb7-4274-99b9-8ef0a42c557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = openai_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def128a-ea9c-49f4-aa0b-35118ee40065",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()\n",
    "print([m.id for m in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e8c57-e154-4c86-9f6a-9b1cbd75b394",
   "metadata": {},
   "source": [
    "### ðŸ§¾ OpenAI Token Pricing (as of April 2025)\n",
    "\n",
    "| Model              | Input Tokens (per 1K) | Output Tokens (per 1K) | Context Window     |\n",
    "|-------------------|-----------------------|-------------------------|--------------------|\n",
    "| **GPT-4 Turbo**    | $0.01                 | $0.03                   | 128K tokens        |\n",
    "| **GPT-4 (legacy)** | $0.03                 | $0.06                   | 8K or 32K tokens   |\n",
    "| **GPT-3.5 Turbo**  | $0.001                | $0.002                  | 16K tokens         |\n",
    "| *GPT-4o* (expected) | *TBD*                | *TBD*                   | *128K tokens*      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fb7f6-fc48-462c-b9b6-6f648bd1dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Send a chat message to GPT-3.5\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a UC Berkeley Economics Student\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain who pays the burden of tariffs\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a89ac7-1882-4866-a6cb-8f040600b652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f6e5c-2b7c-4943-a6ef-8e84e5591548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define token prices (per 1K tokens)\n",
    "token_prices = {\n",
    "    \"gpt-4-turbo\": {\"input\": 0.01, \"output\": 0.03},\n",
    "    \"gpt-4 (legacy)\": {\"input\": 0.03, \"output\": 0.06},\n",
    "    \"gpt-3.5-turbo\": {\"input\": 0.001, \"output\": 0.002},\n",
    "}\n",
    "\n",
    "# Widgets\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=list(token_prices.keys()),\n",
    "    value=\"gpt-3.5-turbo\",\n",
    "    description='Model:',\n",
    ")\n",
    "\n",
    "input_tokens = widgets.IntText(\n",
    "    value=1000,\n",
    "    description='Input Tokens:',\n",
    ")\n",
    "\n",
    "output_tokens = widgets.IntText(\n",
    "    value=500,\n",
    "    description='Output Tokens:',\n",
    ")\n",
    "\n",
    "estimate_button = widgets.Button(\n",
    "    description=\"Estimate Cost\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "cost_display = widgets.Label(value=\"\")\n",
    "\n",
    "# Define the estimator\n",
    "def estimate_cost(b):\n",
    "    model = model_selector.value\n",
    "    input_count = input_tokens.value\n",
    "    output_count = output_tokens.value\n",
    "    prices = token_prices[model]\n",
    "    \n",
    "    cost = (input_count / 1000) * prices[\"input\"] + (output_count / 1000) * prices[\"output\"]\n",
    "    cost_display.value = f\"ðŸ’² Estimated Cost: ${cost:.6f}\"\n",
    "\n",
    "estimate_button.on_click(estimate_cost)\n",
    "\n",
    "# Display everything\n",
    "display(model_selector, input_tokens, output_tokens, estimate_button, cost_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56769326-5e7a-4d92-9edc-a35f65e4fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Send a chat message to GPT-3.5\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a UC Berkeley Economics Student\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain who pays the burden of tariffs\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display response\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# Display token usage\n",
    "print(\"\\nðŸ”¢ Token Usage:\")\n",
    "print(f\"Prompt tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Completion tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Total tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763fc99-1359-4ecb-af54-2c4aacad68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a UC Berkeley Economics Student\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain who pays the burden of tariffs\"}\n",
    "    ],\n",
    "    temperature=0.7,               # creativity level (0 = deterministic, 1 = max randomness)\n",
    "    top_p=1.0,                     # nucleus sampling (used instead of temperature, but can be combined)\n",
    "    presence_penalty=0.5,         # encourages new topics\n",
    "    frequency_penalty=0.3,        # discourages repetition\n",
    "    max_tokens=200,               # max length of the response\n",
    "    stop=None                     # can be a list of strings to stop generation early (e.g., [\"\\n\", \"END\"])\n",
    ")\n",
    "\n",
    "# Display the response text\n",
    "print(\"ðŸ“˜ Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Display token usage\n",
    "print(\"\\nðŸ”¢ Token Usage:\")\n",
    "print(f\"Prompt tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Completion tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Total tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a302fb-08f3-4067-b467-73d92b459ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
